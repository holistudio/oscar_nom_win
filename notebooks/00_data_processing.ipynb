{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd12132",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "The HuggingFace dataset, [Movie-o-Label](https://huggingface.co/datasets/Francis2003/Movie-O-Label), does not contain accurate labels for which movies won an Oscar, only those that earned a nomination. Fortunately, one of Movie-o-Label's [reference datasets](https://github.com/DLu/oscar_data) does contain this information.\n",
    "\n",
    "This notebook correctly labels which movies won an Oscar in the HuggingFace dataset by cross-referencing `FilmId`/`imdb_id` and then saves the `parquet` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import scipy\n",
    "import sklearn \n",
    "import statsmodels\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332308c9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = os.path.join('..','data', 'raw')\n",
    "processed_dir = os.path.join('..','data', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the Hugging Face Hub\n",
    "# This will download the data and cache it locally for future use.\n",
    "ds = load_dataset(os.path.join(raw_dir, 'Movie-O-Label'))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20091fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds['train'].to_pandas()\n",
    "df_val   = ds['validation'].to_pandas()\n",
    "df_test  = ds['test'].to_pandas()\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_train, df_val, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv(os.path.join(raw_dir, 'oscar_data','oscars.csv'),sep='\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = (csv_df['Class'] == 'Writing') & (csv_df['Winner'] == True)\n",
    "oscar_wins_df = csv_df[df_filter]\n",
    "\n",
    "oscar_wins_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd111d9e",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "For every record in `oscar_wins_df` check if it's in the Huggingface dataset. If so, mark as winner in the Huggingface Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for film_id in oscar_wins_df['FilmId']:\n",
    "    for df in dfs:\n",
    "        df_filter = df['imdb_id'] == str(film_id)\n",
    "        filter_df = df[df_filter]\n",
    "        if df_filter.any():\n",
    "            if df_filter.sum() > 1:\n",
    "                print(f\"Weird! Multiple matches found for film_id: {film_id}\")\n",
    "                print(df[df_filter])\n",
    "                print()\n",
    "            df.loc[df_filter, 'winner'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['winner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['winner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa467f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['winner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(os.path.join(processed_dir,'train_clean.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_parquet(os.path.join(processed_dir,'val_clean.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_parquet(os.path.join(processed_dir,'test_clean.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b02ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oscar-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
