{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03fc08aa",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Questions\n",
    "\n",
    "- How many Oscar nominations are there in this dataset? Oscar wins?\n",
    "- Mean and std dev of tokens in the scripts?\n",
    "- Mean and std dev of tokens in the summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import scipy\n",
    "import sklearn \n",
    "import statsmodels\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f629dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d9274",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19209564",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = os.path.join('..','data', 'raw')\n",
    "processed_dir = os.path.join('..','data', 'processed')\n",
    "\n",
    "df_train = pd.read_parquet(os.path.join(processed_dir,'train_clean.parquet'))\n",
    "df_val = pd.read_parquet(os.path.join(processed_dir,'val_clean.parquet'))\n",
    "df_test = pd.read_parquet(os.path.join(processed_dir,'test_clean.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = ['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10601093",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_train, df_val, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train),len(df_val),len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv(os.path.join(raw_dir, 'oscar_data','oscars.csv'),sep='\t')\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69aac1a",
   "metadata": {},
   "source": [
    "## `oscars.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656be60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = csv_df['Class'] == 'Writing'\n",
    "\n",
    "filter_df = csv_df[df_filter]\n",
    "filter_df['Category'].unique()\n",
    "\n",
    "list1 = list(filter_df['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_categories = [a for a in csv_df['Category'].unique() if 'WRITING' in a]\n",
    "writing_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54971be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(writing_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in writing_categories:\n",
    "    if item not in list1:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d294b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = (csv_df['Class'] == 'Writing') & (csv_df['Winner'] == True)\n",
    "oscar_wins_df = csv_df[df_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_wins_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_wins_df[oscar_wins_df['FilmId'] == 'tt1285016']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f082c7",
   "metadata": {},
   "source": [
    "## Oscar noms / wins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dcc9b3",
   "metadata": {},
   "source": [
    "### Oscar nominations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['nominated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce77bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_train['nominated'] == 1\n",
    "df_train[df_filter].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in zip(df_names, dfs):\n",
    "    df_filter = df['nominated'] == 1\n",
    "    pos_fraction = len(df[df_filter]) / len(df)\n",
    "    print(f'{name}: {pos_fraction*100:.2f}% nominated for Oscar in best screenplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda7a6c",
   "metadata": {},
   "source": [
    "### Oscar wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['winner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30042673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['winner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['winner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_test['title'] == 'The Social Network'\n",
    "df_test[df_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in zip(df_names, dfs):\n",
    "    df_filter = df['winner'] == 1\n",
    "    pos_fraction = len(df[df_filter]) / len(df)\n",
    "    print(f'{name}: {pos_fraction*100:.2f}% won Oscar for best screenplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b184010e",
   "metadata": {},
   "source": [
    "## Summary Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60156abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (df_train.iloc[0]['summary'])\n",
    "integers = tokenizer.encode(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b20fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = [[],[],[]]\n",
    "\n",
    "for idx, df in enumerate(dfs):\n",
    "    for i in range(len(df)):\n",
    "        text = (df.iloc[i]['summary'])\n",
    "        integers = tokenizer.encode(text=text)\n",
    "        n_tokens[idx].append(len(integers))\n",
    "\n",
    "global_n_tokens = n_tokens[0] + n_tokens[1] + n_tokens[2]\n",
    "global_n_tokens = np.array(global_n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, n in zip(df_names, n_tokens):\n",
    "    n_array = np.array(n)\n",
    "    print(f'{name} dataset: mean={np.mean(n_array):.1f}, min={np.min(n_array)}, max={np.max(n_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'global dataset: mean={np.mean(global_n_tokens):.1f}, min={np.min(global_n_tokens)}, max={np.max(global_n_tokens)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdc930",
   "metadata": {},
   "source": [
    "## Script Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (df_train.iloc[0]['script_clean'])\n",
    "integers = tokenizer.encode(text=text)\n",
    "len(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = [[],[],[]]\n",
    "\n",
    "for idx, df in enumerate(dfs):\n",
    "    for i in range(len(df)):\n",
    "        text = (df.iloc[i]['script_clean'])\n",
    "        integers = tokenizer.encode(text=text)\n",
    "        n_tokens[idx].append(len(integers))\n",
    "\n",
    "global_n_tokens = n_tokens[0] + n_tokens[1] + n_tokens[2]\n",
    "global_n_tokens = np.array(global_n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, n in zip(df_names, n_tokens):\n",
    "    n_array = np.array(n)\n",
    "    print(f'{name} dataset: mean={np.mean(n_array):.1f}, min={np.min(n_array)}, max={np.max(n_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18780d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'global dataset: mean={np.mean(global_n_tokens):.1f}, min={np.min(global_n_tokens)}, max={np.max(global_n_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc41bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (df_train.iloc[i]['script_clean'])\n",
    "integers = tokenizer.encode(text=text)\n",
    "\n",
    "print(integers[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31af8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oscar-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
